{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636bc112-0167-4a9c-b03a-ace79cd8926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: Developing your Zomato business account and profile is a great way to boost your restaurant’s online reputation\n",
      "1. ('zomato.txt', 13.733532128933936)\n",
      "2. ('paypal.txt', 1.0863426046257378)\n",
      "3. ('swiggy.txt', 0.47561807136786993)\n",
      "4. ('instagram.txt', 0.41642397045854473)\n",
      "5. ('volkswagen.txt', 0.19662525431305533)\n",
      "6. ('shakespeare.txt', 0.11952093253972164)\n",
      "7. ('nike.txt', 0.11201056721619088)\n",
      "8. ('operating.txt', 0.04491234885963554)\n",
      "9. ('messenger.txt', 0.03320901719844228)\n",
      "\n",
      "\n",
      "Query 2: Warwickshire, came from an ancient family and was the heiress to some land\n",
      "1. ('shakespeare.txt', 11.011346010185404)\n",
      "2. ('operating.txt', 0.2080586176747389)\n",
      "3. ('paypal.txt', 0.13174687932980597)\n",
      "4. ('zomato.txt', 0.1069482439155939)\n",
      "5. ('motorola.txt', 0.058489961814339735)\n",
      "6. ('nike.txt', 0.02468155040858179)\n",
      "7. ('instagram.txt', 0.02363078542263073)\n",
      "8. ('swiggy.txt', 0.02363078542263073)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Here we used the same testcases as given in the file in the blackboard\"\"\"\n",
    "\n",
    "\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class VectorSpaceModel:\n",
    "    def __init__(self):\n",
    "        # Dictionary where term maps to a list of (document ID, term frequency)\n",
    "        self.index = defaultdict(list)\n",
    "        # Length of each document for normalization\n",
    "        self.document_lengths = defaultdict(float)\n",
    "        # Total number of documents in the collection\n",
    "        self.num_docs = 0\n",
    "        # Mapping from document ID to document name (file name)\n",
    "        self.doc_names = {}\n",
    "\n",
    "    def index_document(self, doc_id, doc_name, word_list):\n",
    "        \"\"\"Index a document with its term frequencies and store the document's name.\"\"\"\n",
    "        term_freqs = defaultdict(int)\n",
    "        self.num_docs += 1\n",
    "        self.doc_names[doc_id] = doc_name\n",
    "\n",
    "        # Count term frequencies\n",
    "        for word in word_list:\n",
    "            term_freqs[word] += 1\n",
    "\n",
    "        # Add term frequencies to index\n",
    "        for word, freq in term_freqs.items():\n",
    "            self.index[word].append((doc_id, freq))\n",
    "\n",
    "        # Compute document length for normalization\n",
    "        length = sum((1 + math.log10(freq)) ** 2 for freq in term_freqs.values())\n",
    "        self.document_lengths[doc_id] = math.sqrt(length)\n",
    "\n",
    "    def compute_idf(self, word):\n",
    "        \"\"\"Calculate inverse document frequency (IDF) for a word.\"\"\"\n",
    "        doc_freq = len(self.index[word])\n",
    "        if doc_freq == 0:\n",
    "            return 0\n",
    "        return math.log10(self.num_docs / doc_freq)\n",
    "\n",
    "    def compute_tf_idf(self, term_freq, doc_freq):\n",
    "        \"\"\"Compute TF-IDF score based on term frequency and document frequency.\"\"\"\n",
    "        return (1 + math.log10(term_freq)) * self.compute_idf(doc_freq)\n",
    "\n",
    "    def normalize_query(self, query_terms):\n",
    "        \"\"\"Create a normalized vector for the query using TF-IDF scores.\"\"\"\n",
    "        term_freqs = defaultdict(int)\n",
    "        for term in query_terms:\n",
    "            term_freqs[term] += 1\n",
    "\n",
    "        query_vector = {}\n",
    "        query_length = 0\n",
    "        for term, freq in term_freqs.items():\n",
    "            if term in self.index:\n",
    "                tf_idf_value = (1 + math.log10(freq)) * self.compute_idf(term)\n",
    "                query_vector[term] = tf_idf_value\n",
    "                query_length += tf_idf_value ** 2\n",
    "\n",
    "        query_length = math.sqrt(query_length)\n",
    "        for term in query_vector:\n",
    "            query_vector[term] /= query_length\n",
    "\n",
    "        return query_vector\n",
    "\n",
    "    def calculate_similarity(self, query_vector, doc_id):\n",
    "        \"\"\"Calculate cosine similarity between the query and a document.\"\"\"\n",
    "        similarity = 0\n",
    "        for term, query_weight in query_vector.items():\n",
    "            postings = self.index[term]\n",
    "            for doc, term_freq in postings:\n",
    "                if doc == doc_id:\n",
    "                    doc_weight = 1 + math.log10(term_freq)\n",
    "                    similarity += query_weight * doc_weight\n",
    "\n",
    "        return similarity / self.document_lengths[doc_id]\n",
    "\n",
    "    def rank_documents(self, query_terms):\n",
    "        \"\"\"Rank documents by similarity to the query and return the top 10 results.\"\"\"\n",
    "        query_vector = self.normalize_query(query_terms)\n",
    "        doc_scores = defaultdict(float)\n",
    "\n",
    "        for term in query_vector:\n",
    "            postings = self.index[term]\n",
    "            for doc_id, term_freq in postings:\n",
    "                doc_scores[doc_id] += self.calculate_similarity(query_vector, doc_id)\n",
    "\n",
    "        ranked_docs = sorted(doc_scores.items(), key=lambda x: (-x[1], x[0]))\n",
    "        return [(self.doc_names[doc_id], score) for doc_id, score in ranked_docs[:10]]\n",
    "\n",
    "\n",
    "# Function to load document content\n",
    "def load_documents():\n",
    "    doc_content = {\n",
    "        \"zomato.txt\": \"Developing your Zomato business account and profile is a great way to boost your restaurant’s online reputation.\",\n",
    "        \"instagram.txt\": \"Instagram is widely used for building business profiles and engaging with customers.\",\n",
    "        \"swiggy.txt\": \"Swiggy can help you increase your online presence and attract more customers.\",\n",
    "        \"messenger.txt\": \"Messenger platforms can be a powerful tool for customer engagement.\",\n",
    "        \"whatsapp.txt\": \"WhatsApp allows for direct interaction with customers, increasing brand presence.\",\n",
    "        \"shakespeare.txt\": \"Warwickshire, came from an ancient family and was the heiress to some land.\",\n",
    "        \"nike.txt\": \"Nike has a long history of innovation and design in sportswear.\",\n",
    "        \"volkswagen.txt\": \"Volkswagen is a global leader in automotive design.\",\n",
    "        \"motorola.txt\": \"Motorola revolutionized the mobile phone industry with innovative products.\",\n",
    "        \"paypal.txt\": \"PayPal provides a secure and easy way to handle online transactions.\",\n",
    "        \"operating.txt\": \"Operating systems are fundamental to the functioning of computers.\"\n",
    "    }\n",
    "\n",
    "    return doc_content\n",
    "\n",
    "\n",
    "# Main function to execute the process\n",
    "def main():\n",
    "    vsm = VectorSpaceModel()\n",
    "    documents = load_documents()\n",
    "\n",
    "    # Add each document to the vector space model\n",
    "    for doc_id, (doc_name, content) in enumerate(documents.items(), start=1):\n",
    "        words = content.lower().split()  # Tokenize content\n",
    "        vsm.index_document(doc_id, doc_name, words)\n",
    "\n",
    "    # Example queries\n",
    "    queries = [\n",
    "        \"Developing your Zomato business account and profile is a great way to boost your restaurant’s online reputation\",\n",
    "        \"Warwickshire, came from an ancient family and was the heiress to some land\"\n",
    "    ]\n",
    "\n",
    "    for i, query in enumerate(queries, start=1):\n",
    "        query_terms = query.lower().split()  # Tokenize the query\n",
    "        ranked_docs = vsm.rank_documents(query_terms)\n",
    "        print(f\"Query {i}: {query}\")\n",
    "        for rank, (doc_name, score) in enumerate(ranked_docs, start=1):\n",
    "            print(f\"{rank}. ('{doc_name}', {score})\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14410b9d-c4b6-4a77-bb13-cf35e517e3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
